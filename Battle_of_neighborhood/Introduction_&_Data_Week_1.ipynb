{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - The Battle of Neighborhoods (Week 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Estate Analysis: Safest Neighborhood in London Borough\n",
    "#### Author: Soumya Narayanan\n",
    "#### Date: January 07, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Intoduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Background\n",
    "\n",
    "Moving when you have a family can be daunting, especially when you’re moving to a city as diverse as London is. So as part of a career change, when I was considering to set up my new home in London, even though it was exciting, it was certainly not an easy task. Currently settled in a peaceful locality in the suburbs of Michigan, the bustling life and current political scenario of London was daunting to say the least.\n",
    "Upon some research, I could find that the the slump in London’s housing market may be about to end. And this is the right time to invest in a property. \n",
    "\n",
    "However, before making an investment, I decided to do a little research on the best neighborhood. \n",
    "\n",
    "#### 1.2 Problem\n",
    "Data that might contribute to determining the best neighborhood include how safe the neighborhood is, affordability, accessibility and facilities like parks, restaurants etc. This project aims to predict the best neighborhood based on the above factrs.\n",
    "\n",
    "#### 1.3 Interest\n",
    "Obviously, expats who are considering to relocate to London as part of career change could utilise this report for finding a safe borough and district in London for buying/renting a house. People who are currently in London, but has not invested in a house yet due to the current political/economical scenario, could also use this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data acquisition and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the analysis was to find all the boroughs in London. This data could be obtainde from a wiki page, https://en.wikipedia.org/wiki/List_of_London_boroughs. \n",
    "\n",
    "The latest crime data records could not be obtained for the boroughs. However, the data pertaining to year 2016, is there as a kaggle dataset, https://www.kaggle.com/jboysen/london-crime.\n",
    "\n",
    "Next, we can check the affordability of the houses using a dataset from Office for National Statistics.\n",
    "https://webarchive.nationalarchives.gov.uk/20171102125110/https://visual.ons.gov.uk/wp-content/uploads/2017/10/map.csv'\n",
    "\n",
    "During the research, I also came across a survey by itv, which records the happiness index of the people in uk. The link for the report is https://www.itv.com/news/london/2016-08-16/londons-happiest-boroughs-revealed-as-richmond-hits-the-top-spot/. The data from this web page can be scrapped and the best boroughs can be found out.\n",
    "\n",
    "Finally to find the districts in Sutton, which is the best borough for buying a house, we scarp the wiki page: https://en.wikipedia.org/wiki/London_Borough_of_Sutton#Districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To find the London borough names</b>, we use <b>BeautifulSoup</b> to scrap the wikipage. After that string manipulation is done using regular expression and the exact name of the boroughs are extracted.\n",
    "\n",
    "<b>For the crime rate analysis</b>, the data set from Kaggle is downloaded. The dataset consist of\n",
    "1. lsoa_code: code for Lower Super Output Area in Greater London\n",
    "2. borough: Common name for London borough.\n",
    "3. major_category: High level categorization of crime\n",
    "4. minor_category: Low level categorization of crime within major category.\n",
    "5. value: monthly reported count of categorical crime in given borough\n",
    "6. year: Year of reported counts, 2008-2016\n",
    "7. month: Month of reported counts, 1-12\n",
    "\n",
    "The csv file is read using pandas. Only the data from the year 2016 is extracted. If the 'value' column is 0, then is filtered out.\n",
    "Finally the dataset can be grouped together on borough name to get the count/crime rate. \n",
    "\n",
    "<b>For the analysis of price per sq.m of houses in the boroughs</b>, the dataset from https://www.ons.gov.uk/ is extracted. This contains:\n",
    "1. local authority code\n",
    "2. local authority name\n",
    "3. year\n",
    "4. price per m2\n",
    "Only local authority name which was extracted from the wiki page is filtered and taken into a dataset. Next, the local authority code and year can be dropped. This will give the dataset with the borough name and price/m2. The dataset when sorted in the ascending order will give the most affordable areas.\n",
    "\n",
    "<b>For the happiness index</b>, the itv page which contains the happiness index analysis is scrapped and the table with the values are extracted. Next string manipulation is done to get only the borough names in the decreasing order of happiness value. These datas are also converted into a dataframe\n",
    "\n",
    "From the analysis, we conclude the best borough for real estate in London to be Sutton. Next we need to build a dataset with the neighborhoods in Sutton. For that, the wiki page https://en.wikipedia.org/wiki/London_Borough_of_Sutton#Districts is scrapped and the district names are obtained. Borough name will be Sutton. <b>The geographical cordinated are obtained using geopy client</b>.\n",
    "\n",
    "Finally <b>Using Foursquare Location Data</b>, the 100 most popular venues in a radius of 500m for each district is Sutton is obtained. The data obtained is a JSON file, and we need to turn that into a data-frame. This final dataset will contain:\n",
    "1. District\t\n",
    "2. District Latitude\t\n",
    "3. District Longitude\t\n",
    "4. Venue\t\n",
    "5. Venue Latitude\t\n",
    "6. Venue Longitude\t\n",
    "7. Venue Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
